# Data Retrieval

When creating a RAG-enabled chat endpoint, we can either use the `getDataRetriever` method to obtain an instance of a vector store retriever, or we can directly provide configurations for data retriever to the chat endpoint as the `retrieverConfig`.

This may or may not include data ingestion whereby we load the data, generate embeddings and store them in a vector store. To learn about data ingestion, check [Data Ingestion](/rag-guide/data-ingestion).

## Retrieving Data

When a RAG-enabled chat endpoint received a query, it uses the provided data retriever to retrieve the relevant context information from the vector store to which the data retriever belongs.

The underlying process is as follows:

1. **Query Embedding Generation**: Each data retriever is attached to a vector store, and a vector store has an embedding model specified for it. This embedding model is used to generate embedding vectors for the given user query.
2. **Vector Store Search**: The generated embedding vectors are used to search the vector store to retrieve the most relevant context information. You can configure your data retriever to use different types of search algorithms, such as similarity matching or Maximal Marginal Relevance (MMR), or specify the number of documents to retrieve. All such configurations will greatly impact the performance of your RAG chat endpoint. We recommend you start with default parameters, but always test with different configurations to find the best one for your use case.
3. **Conversion to String**: The retrieved context information is converted back to a string format so it can be embedded in the query that will be sent to the LLM model. A specific prompt template maybe used to structure the query and context information in a way that the LLM model can understand and generate a meaningful response.
4. **Response Generation**: The query with the context information is sent to the LLM model, which generates a response based on the query and context information.

## Data Retriever

The `getDataRetriever` method is used to obtain a vector store retriever. The method takes in a configuration object with the following properties:

- `dataType`: The type of data loader to use.
- `filePath`: The path to the file containing the data.
- `jsonLoaderKeysToInclude`: The keys to include when loading JSON data.
- `csvLoaderOptions`: The options for loading CSV data.
- `pdfLoaderOptions`: The options for loading PDF data.
- `dataSplitterType`: The type of data splitter to use.
- `chunkingConfig`: The configuration for chunking the data.
- `splitterConfig`: The configuration for the data splitter.
- `retrievalOptions`: The retrieval options for the retriever.
- `vectorStore`: The vector store to use.
- `embeddingModel`: The embedding model to use.
- `generateEmbeddings`: Whether to generate embeddings.

Below is an example of a custom configured data retriever:

```typescript copy
import { getDataRetriever } from "@oconva/qvikchat/data-retrievers";

// Index inventory data and get retriever
const inventoryDataRetriever = await getDataRetriever({
  dataType: "csv",
  filePath: "data/knowledge-bases/inventory-data.csv",
  generateEmbeddings: true,
  retrievalOptions: {
    k: 10, // return top 10 matching documents
    searchType: "mmr", // use Maximal Marginal Relevance (MMR) for search
  },
});
```

The `getDataRetriever` method returns a retriever instance that can be used to retrieve context information from the vector store. This retriever instance can be passed to the chat endpoint configuration as the `retriever` property.

```typescript copy
import { defineChatEndpoint } from "@oconva/qvikchat/endpoints";

// open-ended RAG chat endpoint
defineChatEndpoint({
  enableRAG: true,
  topic: "Inventory Data", // topic of data for which RAG is enabled
  retriever: inventoryDataRetriever,
});
```

## Endpoint Retriever Config

Instead of creating a data retriever separately, you can also provide the data retriever configuration directly in the chat endpoint configuration. Data retriever will be created using the provided configuration when the chat endpoint is initialized.

Be mindful though that when sharing the same retriever configurations (for example, same data) and the `generateEmbeddings` flag is set to `true`, the data will be loaded and embeddings will be generated each time any chat endpoint using that retriever configuration is initialized. So, if you have multiple chat endpoints that will be sharing the same retriever config and you are generating embeddings for the data, it is recommended to create a retriever instance separately and share it across multiple chat endpoints as the `retriever` instance.

```typescript copy
// Inventory Data chat endpoint with support for chat history, authentication, caching and RAG
defineChatEndpoint({
  endpoint: "rag-chat-inventory",
  enableChatHistory: true,
  chatHistoryStore, // chat history store instance
  enableAuth: true,
  apiKeyStore, // API key store instance
  enableCache: true,
  cacheStore, // cache store instance
  enableRAG: true,
  topic: "Store Inventory Data", // topic of data for which RAG is enabled
  retrieverConfig: {
    dataType: "csv",
    filePath: "rag/knowledge-bases/inventory-data.csv",
    generateEmbeddings: true,
  },
});
```

## Vector Store

The data retriever is attached to a vector store, which is used to store the embeddings generated for the data. The vector store is responsible for storing the embeddings and providing search functionality to retrieve the most relevant context information based on the user query.

By default, QvikChat uses an in-memory vector store. Check [Vector Store](/rag-guide/vector-stores) to learn how to use a hosted vector store supported by LangChain.
