# Open-ended Chat

Unrestricted chat with no restrictions on what topic the user queries can be related to, quite similar to OpenAI's ChatGPT or Google's Gemini front-ends.

In QvikChat, you essentially write the configurations for a chat endpoint to specify the features you want to enable. To make it easier to write these configurations, we provide a TypeScript interface `ChatEndpointConfig` that you can use to define the chat endpoint configurations.

```typescript
import { ChatEndpointConfig } from "@oconva/qvikchat";
```

Below are some examples of the open-ended chat endpoints you can define.

## Open Chat

Unrestricted chat with no additional features enabled.

### Usage

Below is an example of how you can define an open-ended chat endpoint.

Simply, pass the `endpoint` to the `defineChatEndpoint` function to define an open-ended chat endpoint.

```typescript copy
// Open-ended chat endpoint
const endpointConfig: ChatEndpointConfig = {
  endpoint: "chat-open",
};
```

### Input Schema

Expects an object with the following properties:

- `query`: User query to chat agent.

  ```json
  {
    "query": "string"
  }
  ```

### Output Schema

Returns an object with the following properties, depending on the success or failure of the request.

For successful requests, the object will contain:

- `response`: Response to the user query, returned as a string by default.

  ```json
  {
    "response": "string"
  }
  ```

For failed requests, the object will contain:

- `error`: Error message returned by the server.

  ```json
  {
    "error": "string"
  }
  ```

### Testing

Can use commands below to test the endpoint defined in the example above.

Depending on the model being used, you may notice that the LLM will hallucinate the answer to the second question. This is because we aren't providing the context in which we are asking the question and because there is no conversation history to refer to.

By default, QvikChat uses system prompts that help reduce LLM hallucinations, therefore, you may observe that for the second question, LLM model may clarify and ask for more information, inside of making up an answer by assuming what you mean by "it".

```bash copy
curl -X POST "http://127.0.0.1:3400/chat-open" -H "Content-Type: application/json"  -d '{"data": { "query": "Answer in one sentence: What is Firebase Firestore?" } }'

curl -X POST "http://127.0.0.1:3400/chat-open" -H "Content-Type: application/json"  -d '{"data": { "query": "Can it be used for authentication?" } }'
```

**Genkit Developer UI**

You could also start the Genkit Developer UI to test above:

```bash copy
npx genkit start
```

Endpoint to test: `chat-open`

## Open Chat with History

Unresticted chat with chat history support.

### Usage

Below is an example of how you can define an open-ended chat endpoint that supports chat history. Simply, set the `enableChatHistory` flag to `true` and provide an a chat history store. For testing, you may use the in-memory chat history store.

```typescript copy
import { InMemoryChatHistoryStore } from "@oconva/qvikchat/history";

// Open-ended chat endpoint with support for chat history
const endpointConfig: ChatEndpointConfig = {
  endpoint: "chat-open-history",
  enableChatHistory: true,
  chatHistoryStore: new InMemoryChatHistoryStore(),
};
```

### Input Schema

Expects an object with the following properties:

- `query`: User query to chat agent.
- `chatId`: Optional chat ID to continue the chat history. If not provided, a new chat history will be created, and the chat ID for this chat history will be returned with the response. This chat ID can be sent in further requests to continue a specific conversation. If the provided chat ID is not valid or not found, as error is returned.

  ```json
  {
    "query": "string",
    "chatId": "string"
  }
  ```

### Output Schema

Returns an object with the following properties, depending on the success or failure of the request.

For successful requests, the object will contain:

- `response`: Chat agent response to the user query, returned as a string by default.
- `chatId`: Chat ID for the current chat history. This can be used to continue the chat history in further requests.

  ```json
  {
    "response": "string",
    "chatId": "string"
  }
  ```

For failed requests, the object will contain:

- `error`: Error message returned by the server.

  ```json
  {
    "error": "string"
  }
  ```

### Testing

Can use commands below to test the endpoint defined in the example above.

On running the first example, you should receive an object as a response with the chat ID for the chat history. Add this chat ID to the second example to continue the chat history.

```bash copy
curl -X POST "http://127.0.0.1:3400/chat-open-history" -H "Content-Type: application/json"  -d '{"data": { "query": "Answer in one sentence: What is Firebase Firestore?" } }'

curl -X POST "http://127.0.0.1:3400/chat-open-history" -H "Content-Type: application/json"  -d '{"data": {"query": "Can it be used for authentication?", "chatId": "<enter chat id here>"} }'
```

**Genkit Developer UI**

You could also start the Genkit Developer UI to test above:

```bash copy
npx genkit start
```

Endpoint to test: `chat-open-history`

## Open Chat with Chat History, Caching, and Authentication

Unrestricted chat with chat history support, response caching, and API key authentication.

### Usage

Below is an example of how you can define an open-ended chat endpoint that supports chat history, response caching, and API key authentication. Simply, set the `enableChatHistory`, `enableAuth`, and `enableCache` flags to `true` and provide a chat history store, an API key store and cache store. For testing, you may use the in-memory stores.

Below example is for testing purposes only. In production, you should use a secure API key store and cache store (e.g. FirestoreAPIKeyStore, FirestoreChatHistoryStore, etc.).

```typescript copy
// Initialize API key store
const testAPIKeyStore = new InMemoryAPIKeyStore();
// add a test API key
const key = "test-api-key";
testAPIKeyStore.addKey(key, {
  uid: "test-user",
  status: "active",
  endpoints: "all", // allow access to all endpoints
});

// Open-ended chat endpoint with support for chat history, authentication, and caching
const endpointConfig: ChatEndpointConfig = {
  endpoint: "chat-open-history-auth-cached",
  enableChatHistory: true,
  chatHistoryStore: new InMemoryChatHistoryStore(),
  enableAuth: true,
  apiKeyStore: testAPIKeyStore,
  enableCache: true,
  cacheStore: new InMemoryCacheStore(),
};
```

### Input Schema

Request header requires an API key for authentication:

- `key`: API key for authentication. The API key must be owned by the user making the request, and should have authorization to access the chat endpoint.

Expects an object with the following properties:

- `query`: User query to chat agent.
- `uid`: User ID of the user making the query. Required to assess if user is authorized to access the chat endpoint. The API key provided in headers must be owned by this user.
- `chatId`: Optional chat ID to continue the chat history. If not provided, a new chat history will be created, and the chat ID for this chat history will be returned with the response. This chat ID can be sent in further requests to continue a specific conversation. If the provided chat ID is not valid or not found, as error is returned.

  ```json
  {
    "query": "string",
    "uid": "string",
    "chatId": "string"
  }
  ```

### Output Schema

Returns an object with the following properties, depending on the success or failure of the request.

For successful requests, the object will contain:

- `response`: Chat agent response to the user query, returned as a string by default.
- `chatId`: Chat ID for the current chat history. This can be used to continue the chat history in further requests.

  ```json
  {
    "response": "string",
    "chatId": "string"
  }
  ```

For failed requests, the object will contain:

- `error`: Error message returned by the server.

  ```json
  {
    "error": "string"
  }
  ```

### Testing

Can use commands below to test the endpoint defined in the example above.

On running the first example, you should receive an object as a response with the chat ID for the chat history. Add this chat ID to the second example to continue the chat history.

```bash copy
curl -X POST "http://127.0.0.1:3400/chat-open-history-auth-cached" -H "Content-Type: application/json" -H "Authorization: test-api-key" -d '{"data": { "query": "Answer in one sentence: What is Firebase Firestore?", "uid": "test-user" } }'

curl -X POST "http://127.0.0.1:3400/chat-open-history-auth-cached" -H "Content-Type: application/json" -H "Authorization: test-api-key" -d '{"data": {"query": "Can it be used for authentication?", "uid": "test-user", "chatId": "<enter chat id here>"} }'
```

**Genkit Developer UI**

You could also start the Genkit Developer UI to test above:

```bash copy
npx genkit start
```

Endpoint to test: `chat-open-history-auth-cached`

## Configurations

As you can see from above, its quite easy to turn features on and off. For all chat endpoint configurations, please check [Chat Endpoint Configurations](/chat-endpoints/chat-endpoint-configurations).
