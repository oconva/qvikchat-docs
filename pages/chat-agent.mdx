import { Notice } from "../components/notice";

# Chat Agent

Chat Agent class provides the methods required to interact with the LLM model and generate responses to user queries. Each chat agent instance can be configured to use specific LLM model, system prompt, chat prompt, tools and more.

Behind the scenes, each chat endpoint uses an instance of `ChatAgent` to process user queries and generate responses. However, you don't have to create a chat agent instance manually when defining a chat endpoint. Instead, you can provide the chat agent configuration directly in the chat endpoint configuration.

## Endpoint Chat Agent Config

When defining a new endpoint, you can configure which LLM model to use, the system prompt, chat prompt, tools and more, using the `chatAgentConfig` property.

```typescript copy
import { defineChatEndpoint } from "@oconva/qvikchat/endpoints";

// Define a chat endpoint with a specific chat agent configurations
defineChatEndpoint({
  endpoint: "chat",
  topic: "inventory data",
  chatAgentConfig: {
    model: "gemini15Pro",
    modelConfig: {
      version: "latest",
      temperature: 0.5,
      maxOutputTokens: 2048,
      safetySettings: [
        {
          category: "HARM_CATEGORY_DANGEROUS_CONTENT",
          threshold: "BLOCK_LOW_AND_ABOVE",
        },
      ],
    },
  },
});
```

## Chat Agent Class

The `ChatAgent` class provides the methods required to interact with the LLM model and generate responses to user queries. You may, if you want to, use the chat agent class directly to generate responses to user queries.

Below documentation provides an overview of the `ChatAgent` class and its methods, but this knowledge is not required to define a chat endpoint.

## Types of Chat Agents

```typescript copy
//Represents the type of chat agent
export type ChatAgentType = "open-ended" | "close-ended" | "rag";
```

The `ChatAgent` class can be used to create different types of chat agents based on the `ChatAgentType`:

- `open-ended`: An open-ended chat agent that can generate responses to user queries without any constraints.
- `close-ended`: A close-ended chat agent that only generate responses to queries that are related to a specific **topic**.
- `rag`: A chat agent that uses the Retrieval-Augmented Generation (RAG) model to generate responses to user queries.

Example of defining a `close-ended` chat agent:

```typescript copy
import { ChatAgent } from "@oconva/qvikchat/agents";

// Define a close-ended chat agent
const closeEndedChatAgent = new ChatAgent({
  agentType: "close-ended",
  topic: "Store Inventory Data",
});
```

## LLM Model

You can configure the chat agent to use a specific **_supported_** LLM model.

<Notice>
  The model name that you provide to the `ChatAgent` instance must be one of the
  supported LLM models, or name of a model that you've setup when configuring
  Genkit (`setupGenkit`).
</Notice>

### Supported LLM Models

You can provide one of the following model names for the `model` property when creating a `ChatAgent` instance:

```
gemini10Pro
gemini15Pro
gemini15Flash
geminiProVision
gpt35Turbo
gpt4o
gpt4Turbo
gpt4Vision
gpt4
```

### Specifying Model

```typescript copy {7}
import { ChatAgent } from "@oconva/qvikchat/agents";

// Define a close-ended chat agent with a specific LLM model
const closeEndedChatAgent = new ChatAgent({
  agentType: "close-ended",
  topic: "Store Inventory Data",
  model: "gemini15Flash",
});
```

### Configuring Model

You can, optionally, also provide additional configuration options for the LLM model.

```typescript copy {7-17}
import { ChatAgent } from "@oconva/qvikchat/agents";

// Define a chat agent with a specific LLM model and configuration
const chatAgent = new ChatAgent({
  topic: "Store Inventory Data",
  model: "gemini15Flash",
  modelConfig: {
    version: "latest",
    temperature: 0.5,
    maxOutputTokens: 2048,
    safetySettings: [
      {
        category: "HARM_CATEGORY_DANGEROUS_CONTENT",
        threshold: "BLOCK_LOW_AND_ABOVE",
      },
    ],
  },
});
```

## All Chat Agent Configurations

```typescript
/**
 * Represents the type of chat agent.
 */
export type ChatAgentType = "open-ended" | "close-ended" | "rag";

/**
 * Represents the configuration for the agent type.
 * @property agentType - The type of agent.
 * @property topic - The topic for the agent type.
 */
export type AgentTypeConfig =
  | {
      agentType?: "open-ended";
    }
  | {
      agentType: "close-ended" | "rag";
      topic: string;
    };

/**
 * Represents the configuration for the chat agent.
 *
 * @property agentType - The type of agent.
 * @property topic - The topic for the chat agent.
 * @property systemPrompt - The system prompt for the chat agent.
 * @property chatPrompt - The chat prompt for the chat agent.
 * @property tools - Tools for the chat agent.
 * @property model - The supported model to use for chat completion.
 * @property modelConfig - The model configuration.
 */
export type ChatAgentConfig = {
  systemPrompt?: Dotprompt;
  chatPrompt?: Dotprompt;
  tools?: ToolArgument[];
  model?: SupportedModels;
  modelConfig?: ModelConfig;
} & AgentTypeConfig;

type DefaultChatAgentConfigType = {
  agentType: ChatAgentType;
  model: SupportedModels;
};
```

## Default Chat Agent Configuration

```typescript
/**
 * Represents the default chat agent configuration.
 */
export const defaultChatAgentConfig: DefaultChatAgentConfigType = {
  agentType: "open-ended",
  model: "gemini15Flash",
};
```

## Generating Responses

You can generate responses to user queries using the `generateResponse` method of the `ChatAgent` class.

```typescript copy
import { ChatAgent } from "@oconva/qvikchat/agents";

// Define a chat agent
const chatAgent = new ChatAgent();

// Generate a response
const response = await chatAgent.generateResponse({
  query: "What is the capital of France?",
});
```

### Response Generation Parameters

Depending on your use case, you can provide additional parameters when generating a response.

```typescript copy
/**
 * Represents the properties for generating a response.
 *
 * @property query - The query string.
 * @property context - The context object.
 * @property chatId - The ID of the chat history.
 * @property history - The chat history.
 * @property enableChatHistory - Indicates whether to use chat history.
 * @property chatHistoryStore - The chat history store.
 * @property tools - The tool arguments.
 * @property model - The supported model.
 * @property modelConfig - The model configuration.
 * @property systemPrompt - The system prompt.
 * @property chatPrompt - The chat prompt.
 */
export type GenerateResponseProps = {
  query: string;
  context?: string;
  chatId?: string;
  tools?: ToolArgument[];
  model?: SupportedModels;
  modelConfig?: ModelConfig;
  systemPrompt?: Dotprompt;
  chatPrompt?: Dotprompt;
} & GenerateResponseHistoryProps;

/**
 * Represents the properties for generating a response with chat history.
 */
export type GenerateResponseHistoryProps =
  | {
      enableChatHistory: true;
      chatId?: string;
      history?: MessageData[];
      chatHistoryStore: ChatHistoryStore;
    }
  | {
      enableChatHistory?: false;
    };
```
